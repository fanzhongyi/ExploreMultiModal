defaults:
  - _self_

phase: 'pretrain_vis'


start_epoch : 0
epochs : 10
warmup_epochs : 2
warmup_steps: 2
weight_decay : 0.1
weight_decay_end: 0.1
base_lr : 1e-4
warmup_lr : 5e-7
min_lr : 5E-6

normlize_target: true
# Clip gradient norm
clip_grad : 5.0
# Auto resume from latest checkpoint
auto_resume : true
# resume checkpoint filepath or url
resume: ''
# Gradient accumulation steps
accumulation_steps : 0
# Whether to use gradient checkpointing to save memory
use_checkpoint : false
# Frequency to save checkpoint
save_freq : 7
# Frequency to logging info
print_freq : 10

lr_scheduler:
  name : 'cosine'
# Epoch interval to decay LR, used in StepLRScheduler
  decay_epochs : 30
# LR decay rate, used in StepLRScheduler
  decay_rate : 0.1

opt:
  name : 'adamw'
  # Optimizer Epsilon
  eps : 1e-8
  # Optimizer Betas
  betas : [0.9, 0.999]
  # SGD momentum
  momentum : 0.9
